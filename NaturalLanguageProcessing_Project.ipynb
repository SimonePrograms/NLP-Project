{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <center><i>Twitter Sentiment Analysis with Natural Language Processing</i></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <i>Steps I will be taking:</i>\n",
    "\n",
    "### 1. Record Twitter Data\n",
    "### 2. Data Pre Processing\n",
    "### 3. Split Data between Training and Testing sets.\n",
    "### 4. Implement Logistic Regression Model for Positive Tweet or Negatvie Tweet reads.\n",
    "### 5. Feed Test set of data to the Trained Logistic Regression Model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <i>Libraries needed for this project</i>\n",
    "\n",
    "### 1. Kaggle\n",
    "### 2. Numpy\n",
    "### 3. Pandas\n",
    "### 4. Regular Expressions\n",
    "### 5. Stop Words (from NLTK)\n",
    "### 6. PorterStemmer (from NLTK)\n",
    "### 7. TfidVectorizer (from SKLEARN)\n",
    "### 8. TrainTestSplit (from SKLEARN)\n",
    "### 9. LogisticRegression (from SKLEARN)\n",
    "### 10. Accuracy_score (from SKLEARN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><i>Importing Twitter Sentimnent Analysis Dataset</i></center>\n",
    "\n",
    "### <center>This is the sentiment140 dataset. It contains 1,600,000 tweets extracted using the twitter api . The tweets have been annotated (0 = negative, 2 - neutral, 4 = positive) and they can be used to detect sentiment.</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.6.17 / client 1.6.14)\n",
      "Dataset URL: https://www.kaggle.com/datasets/kazanova/sentiment140\n",
      "License(s): other\n",
      "sentiment140.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "# API to fetch the dataset from Kaggle\n",
    "\n",
    "!kaggle datasets download -d kazanova/sentiment140\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\simon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "# print the stopwords in english ( words that dont add context to the NLP)\n",
    "\n",
    "print(stopwords.words(\"english\"))\n",
    "\n",
    "# remove the stop words from the large dataset to make the model more efficient\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <i>Data Processing</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600000, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# naming columns\n",
    "\n",
    "columns = [\"target\", \"id\",\"date\", \"flag\", \"user\", \"Tweet\"]\n",
    "\n",
    "#loading the data from the pandas dataframe\n",
    "\n",
    "twtData = pd.read_csv(\"C:/Users/simon/Python/Python_Lessons/twitter_dataset.csv\", names = columns, encoding = \"ISO-8859-1\")\n",
    "\n",
    "# interleaved_df = pd.concat([twtData[twtData['target'] == 0].iloc[:min(len(twtData[twtData['target'] == 0]), len(twtData[twtData['target'] == 1]))], twtData[twtData['target'] == 1].iloc[:min(len(twtData[twtData['target'] == 0]), len(twtData[twtData['target'] == 1]))]]).sort_index(kind='merge')\n",
    "\n",
    "\n",
    "# check the number of rows and colunmns\n",
    "\n",
    "twtData.shape # will result in (1600000, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive_df = twtData[twtData['target'] == 1]\n",
    "# negative_df = twtData[twtData['target'] == 0]\n",
    "\n",
    "# # Determine the minimum length to ensure equal alternation\n",
    "# min_length = min(len(positive_df), len(negative_df))\n",
    "\n",
    "# # Slice both DataFrames to the minimum length\n",
    "# positive_df = positive_df.iloc[:min_length]\n",
    "# negative_df = negative_df.iloc[:min_length]\n",
    "\n",
    "# # Interleave the rows\n",
    "# interleaved_df = pd.concat([positive_df, negative_df]).sort_index(kind='merge')\n",
    "\n",
    "# # Reset the index\n",
    "# interleaved_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# # Now you can use interleaved_df or further slice it if needed\n",
    "# newdata = interleaved_df.iloc[:10000]\n",
    "\n",
    "# # Apply the stemming function to this sample\n",
    "# # newdata['stemmed_content'] = newdata['Tweet'].apply(stemming)\n",
    "\n",
    "# # Check the result\n",
    "# newdata.head()\n",
    "# newdata.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [target, id, date, flag, user, Tweet]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdata.head() # this prints the first 5 rows of the dataset by default parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target    0\n",
       "id        0\n",
       "date      0\n",
       "flag      0\n",
       "user      0\n",
       "Tweet     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check /count for missing values in the dataset\n",
    "\n",
    "twtData.isnull().sum() # this sums all the missing values together to count them in a single code line\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    800000\n",
       "4    800000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the distribution of target column. How many 0s and 4s are therein the entire dataste?\n",
    "\n",
    "twtData[\"target\"].value_counts() # distribution is equal in this data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><u>Important Note</u></center>\n",
    "\n",
    "## <center><i>If the Distribution of a dataste is NOT equal, the machine learning model will not work properly for the project intended. <br> <br> Therefore it is necessary to use downsampling in order to equalise the distributions of the different sets of data for Optimization.</i></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positive</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     target          id                          date      flag  \\\n",
       "0  Positive  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1  Positive  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2  Positive  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3  Positive  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4  Positive  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                              Tweet  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the names of the labels, conveting themfrom 0 to \"Positive\" and 4 to \"Negative\"\n",
    "\n",
    "twtData.replace({\"target\":{4:\"Negative\"}}, inplace = True)\n",
    "twtData.replace({\"target\":{0:\"Positive\"}}, inplace = True)\n",
    "twtData.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_df = twtData[twtData['target'] == \"Positive\"]\n",
    "negative_df = twtData[twtData['target'] == \"Negative\"]\n",
    "\n",
    "positive_df = positive_df.iloc[:10000]\n",
    "negative_df = negative_df.iloc[:10000]\n",
    "\n",
    "newdata = pd.concat([negative_df, positive_df]) # Concatenated the 2 categories into a new smaller dataframe called newdata so that it's quicker to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 6)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(positive_df.shape)\n",
    "negative_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming\n",
    "\n",
    "## Process of reducing a word to its root word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'newdata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 21\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stemmed_content\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# twtData[\"stemmed_content\"] = twtData[\"Tweet\"].apply(stemming) --> # 50 minutes to complete this execution as it takes into consideration ALL of the dataframe.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# So for the sake of time, I will use the .loc accessor to select the frist 20,000 rows of the dataframe only.\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[43mnewdata\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\n\u001b[0;32m     22\u001b[0m newdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstemmed_content\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m newdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTweet\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(stemming) \u001b[38;5;66;03m# This will save in the \"stemmed_content\" column for those rows\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'newdata' is not defined"
     ]
    }
   ],
   "source": [
    "# Reducing each word i the entire databae to their root forms with PorterStemmer\n",
    "\n",
    "stemmed = PorterStemmer()\n",
    "\n",
    "def stemming(content):\n",
    "\n",
    "    stemmed_content = re.sub(\"[^a-zA-Z]\", \" \", content) # this removes all the characters that are not alphabetical\n",
    "    stemmed_content = stemmed_content.lower() # thsi will turn allt he words into lower case\n",
    "    stemmed_content = stemmed_content.split()\n",
    "    stemmed_content = [stemmed.stem(word) for word in stemmed_content if not word in stopwords.words(\"english\")]\n",
    "    stemmed_content = \" \".join(stemmed_content)\n",
    "\n",
    "    return stemmed_content\n",
    "\n",
    "# twtData[\"stemmed_content\"] = twtData[\"Tweet\"].apply(stemming) --> # 50 minutes to complete this execution as it takes into consideration ALL of the dataframe.\n",
    "\n",
    "# So for the sake of time, I will use the .loc accessor to select the frist 20,000 rows of the dataframe only.\n",
    "\n",
    "\n",
    "\n",
    "newdata[\"target\"].value_counts()\n",
    "newdata[\"stemmed_content\"] = newdata[\"Tweet\"].apply(stemming) # This will save in the \"stemmed_content\" column for those rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800000                     love health uandpet u guy r best\n",
      "800001        im meet one besti tonight cant wait girl talk\n",
      "800002    darealsunisakim thank twitter add sunisa got m...\n",
      "800003    sick realli cheap hurt much eat real food plu ...\n",
      "800004                         lovesbrooklyn effect everyon\n",
      "                                ...                        \n",
      "9995                                                aww sad\n",
      "9996                           stupid dvd stuf good bit jaw\n",
      "9997      dandi sephi close friend famili afraid work co...\n",
      "9998                        crap look last tweet earli like\n",
      "9999                                     anoth rainboot day\n",
      "Name: stemmed_content, Length: 20000, dtype: object \n",
      "\n",
      "\n",
      "####### BREAK ######\n",
      "\n",
      "\n",
      " 800000    Negative\n",
      "800001    Negative\n",
      "800002    Negative\n",
      "800003    Negative\n",
      "800004    Negative\n",
      "            ...   \n",
      "9995      Positive\n",
      "9996      Positive\n",
      "9997      Positive\n",
      "9998      Positive\n",
      "9999      Positive\n",
      "Name: target, Length: 20000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(newdata[\"stemmed_content\"], \"\\n\\n\\n####### BREAK ######\\n\\n\\n\", newdata[\"target\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separating Data and Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed Content:\n",
      " ['love health uandpet u guy r best'\n",
      " 'im meet one besti tonight cant wait girl talk'\n",
      " 'darealsunisakim thank twitter add sunisa got meet hin show dc area sweetheart'\n",
      " ... 'dandi sephi close friend famili afraid work colleagu'\n",
      " 'crap look last tweet earli like' 'anoth rainboot day'] \n",
      "\n",
      "Targets:\n",
      " ['Negative' 'Negative' 'Negative' ... 'Positive' 'Positive' 'Positive']\n"
     ]
    }
   ],
   "source": [
    "x = newdata[\"stemmed_content\"].values\n",
    "y = newdata[\"target\"].values\n",
    "print(\"Stemmed Content:\\n\", x, \"\\n\")\n",
    "print(\"Targets:\\n\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000,) (16000,) (4000,)\n",
      "['simultech yeah weird line long assum world continu fine without'\n",
      " 'aponderingheart ye watch first episod far love love love love nd episod tonight'\n",
      " 'sara xox leav make sad' ...\n",
      " 'listen music talk besti amp make plan see hm movi friday'\n",
      " 'seekin new job' 'hero soooo bore ugh found episod season']\n",
      "\n",
      "\n",
      "['twitter wound'\n",
      " 'nsingman reaction urban crime view held outsid citi con equival death penalti'\n",
      " 'crush wyatt cenac much daili show suppos' ... 'sleep star'\n",
      " 'sleepi star war loner' 'maxim megeld useless sleep fair want fun well']\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, train_size=0.8, stratify=y, random_state=2)\n",
    "\n",
    "\n",
    "print(x.shape, x_train.shape, x_test.shape)\n",
    "\n",
    "print(x_train)\n",
    "print(\"\\n\")\n",
    "print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the textual data to numerical data\n",
    "\n",
    "vectorizer = TfidfVectorizer() # learns how many times each word is repeated and sets a value for importance based on that.\n",
    "# This creates a bias from pattern recognition based on a word that is most present in a positive or negative sentence.\n",
    "\n",
    "x_train = vectorizer.fit_transform(x_train) # transforms all the values of importance into the training data so that it is all the same.\n",
    "x_test = vectorizer.transform(x_test) # only use fit_transform for training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 119118 stored elements and shape (16000, 20096)>\n",
      "  Coords\tValues\n",
      "  (0, 15814)\t0.4381072802450677\n",
      "  (0, 19827)\t0.2356575557396753\n",
      "  (0, 19133)\t0.3138237953661589\n",
      "  (0, 10115)\t0.3239360884271173\n",
      "  (0, 10277)\t0.2376568868524926\n",
      "  (0, 1050)\t0.3772952363411329\n",
      "  (0, 19510)\t0.2615287190021183\n",
      "  (0, 3517)\t0.3417224710651225\n",
      "  (0, 5990)\t0.2969060869969978\n",
      "  (0, 19385)\t0.27739922435336506\n",
      "  (1, 850)\t0.36176943786571214\n",
      "  (1, 19821)\t0.19739043202681927\n",
      "  (1, 19044)\t0.16975754260193868\n",
      "  (1, 6014)\t0.1989742075409638\n",
      "  (1, 5446)\t0.4918071986566638\n",
      "  (1, 5821)\t0.228602451302166\n",
      "  (1, 10359)\t0.6044384571894548\n",
      "  (1, 12067)\t0.25236030185488223\n",
      "  (1, 17853)\t0.19643462210124493\n",
      "  (2, 15102)\t0.587854324427436\n",
      "  (2, 19694)\t0.5497621483278535\n",
      "  (2, 9917)\t0.390550622656313\n",
      "  (2, 10613)\t0.2987347707608602\n",
      "  (2, 14992)\t0.3322899658417758\n",
      "  (3, 14992)\t0.1828093476305661\n",
      "  :\t:\n",
      "  (15996, 16766)\t0.273763136980639\n",
      "  (15996, 16465)\t0.3929119386042842\n",
      "  (15996, 16467)\t0.3929119386042842\n",
      "  (15996, 12393)\t0.42221498535083896\n",
      "  (15997, 10613)\t0.22578216577515134\n",
      "  (15997, 15368)\t0.22400491401194267\n",
      "  (15997, 610)\t0.2304052442229086\n",
      "  (15997, 11842)\t0.298058118094827\n",
      "  (15997, 13478)\t0.3016498932261573\n",
      "  (15997, 11683)\t0.2975658513597601\n",
      "  (15997, 10152)\t0.28585877301576285\n",
      "  (15997, 6350)\t0.31165655604937337\n",
      "  (15997, 17120)\t0.27869564971220245\n",
      "  (15997, 7649)\t0.3904870307713521\n",
      "  (15997, 1635)\t0.4103467636062923\n",
      "  (15998, 8890)\t0.48005210689448063\n",
      "  (15998, 12173)\t0.36421269801097833\n",
      "  (15998, 15375)\t0.7980595750153832\n",
      "  (15999, 5446)\t0.38959370861064485\n",
      "  (15999, 6229)\t0.3475184371329123\n",
      "  (15999, 2022)\t0.32975631619533896\n",
      "  (15999, 18374)\t0.3528196977047204\n",
      "  (15999, 7530)\t0.4217097904807743\n",
      "  (15999, 15339)\t0.38959370861064485\n",
      "  (15999, 16201)\t0.4057145618882773\n"
     ]
    }
   ],
   "source": [
    "print(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 26103 stored elements and shape (4000, 20096)>\n",
      "  Coords\tValues\n",
      "  (0, 18276)\t0.42182268311695575\n",
      "  (0, 19542)\t0.9066783464978152\n",
      "  (1, 3149)\t0.2749160841012165\n",
      "  (1, 3434)\t0.3740247821248823\n",
      "  (1, 4204)\t0.2945152140509762\n",
      "  (1, 7467)\t0.3409505592120597\n",
      "  (1, 12859)\t0.24684517244101775\n",
      "  (1, 13188)\t0.38985208913922165\n",
      "  (1, 14255)\t0.3740247821248823\n",
      "  (1, 18576)\t0.38985208913922165\n",
      "  (1, 18811)\t0.2770265949524451\n",
      "  (2, 3784)\t0.5447862708548599\n",
      "  (2, 3943)\t0.5243856771028235\n",
      "  (2, 11786)\t0.31462080672047793\n",
      "  (2, 15701)\t0.3666629299976556\n",
      "  (2, 16917)\t0.44136110440495174\n",
      "  (3, 8313)\t0.6513933394426372\n",
      "  (3, 12681)\t0.47473074466740617\n",
      "  (3, 16092)\t0.43828722873878884\n",
      "  (3, 16238)\t0.39777096741940815\n",
      "  (4, 2843)\t0.5104509811556713\n",
      "  (4, 4138)\t0.23602257895681145\n",
      "  (4, 6203)\t0.4191387435919197\n",
      "  (4, 9815)\t0.3068519368628186\n",
      "  (4, 13329)\t0.37097495323324\n",
      "  :\t:\n",
      "  (3995, 7766)\t0.2255061398918757\n",
      "  (3995, 7859)\t0.20593030015122607\n",
      "  (3995, 8638)\t0.4176589898517443\n",
      "  (3995, 12625)\t0.4354402828116663\n",
      "  (3995, 16238)\t0.25504193915598217\n",
      "  (3995, 16628)\t0.22603706009035782\n",
      "  (3995, 17674)\t0.20917151400550027\n",
      "  (3995, 18269)\t0.2744033573382988\n",
      "  (3995, 19085)\t0.3043868447273488\n",
      "  (3996, 866)\t0.8144210468509763\n",
      "  (3996, 3201)\t0.5802743820350507\n",
      "  (3997, 15952)\t0.5608450620505628\n",
      "  (3997, 16495)\t0.8279207790444083\n",
      "  (3998, 10275)\t0.6146524548914586\n",
      "  (3998, 15953)\t0.4440172075081598\n",
      "  (3998, 16495)\t0.4244184005326887\n",
      "  (3998, 19010)\t0.49489402948695344\n",
      "  (3999, 5768)\t0.36633780493495927\n",
      "  (3999, 6443)\t0.2609358820771059\n",
      "  (3999, 10943)\t0.47292197129693386\n",
      "  (3999, 11061)\t0.47292197129693386\n",
      "  (3999, 15952)\t0.23057259115709813\n",
      "  (3999, 18600)\t0.4477095052732817\n",
      "  (3999, 19007)\t0.21535349996767886\n",
      "  (3999, 19143)\t0.224530722610623\n"
     ]
    }
   ],
   "source": [
    "print(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <i>Training the Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter = 1000) # maximum number of times the model can go through the data to achieve the maximum accuracy\n",
    "\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <i> Model Evaluation & Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the TRAINING data:\n",
      " 0.849125\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(x_train)\n",
    "accuracy = accuracy_score(y_train, prediction)\n",
    " \n",
    "print(\"Accuracy score of the TRAINING data:\\n\", accuracy) # Over 80% accuracy, pretty good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the TESTING data:\n",
      " 0.7335\n"
     ]
    }
   ],
   "source": [
    "prediction_test = model.predict(x_test)\n",
    "accuracy_test = accuracy_score(y_test, prediction_test)\n",
    " \n",
    "print(\"Accuracy score of the TESTING data:\\n\", accuracy_test) # Over 70% accuracy, still pretty good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m f1_score\n\u001b[1;32m----> 3\u001b[0m sklearn\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mf1_score(\u001b[43my_test\u001b[49m, prediction_test , labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.metrics import f1_score\n",
    "sklearn.metrics.f1_score(y_test, prediction_test , labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <i> Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Twitter_model.joblib']"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "#this allows saving and loading models\n",
    "\n",
    "joblib.dump(model, \"Twitter_model.joblib\")\n",
    "# file stored in the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Positive' 'Negative' 'Negative' 'Positive' 'Positive' 'Negative'\n",
      " 'Positive' 'Negative' 'Positive' 'Negative' 'Negative' 'Negative'\n",
      " 'Positive' 'Positive' 'Negative' 'Positive' 'Negative' 'Positive'\n",
      " 'Negative' 'Negative']\n",
      "\n",
      "\n",
      "\n",
      "['Negative' 'Positive' 'Positive' 'Positive' 'Positive' 'Negative'\n",
      " 'Positive' 'Negative' 'Negative' 'Negative' 'Positive' 'Negative'\n",
      " 'Positive' 'Positive' 'Negative' 'Positive' 'Negative' 'Positive'\n",
      " 'Negative' 'Negative']\n",
      "\n",
      "\n",
      "\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "x_new = x_test[0:20]\n",
    "print(y_test[0:20])\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "prediction1 = model.predict(x_new)\n",
    "print(prediction1)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "accuracy1 = accuracy_score(y_test[0:20], prediction1)\n",
    "print(accuracy1)  # 75% of accuracy, pretty good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <i> <center> The Natural Language Processing model has 75% accuracy in real time therefore it is pretty good at predicting results. And can be loaded through the joblib.import function. <br><br> <u> End of NLP Project</u>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
